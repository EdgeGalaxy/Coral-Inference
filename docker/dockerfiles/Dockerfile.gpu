# 构建阶段
FROM nvcr.io/nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04 AS builder

ENV TZ="Asia/Shanghai"
ARG DEBIAN_FRONTEND=noninteractive

# Set timezone
RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && \
    echo 'Asia/Shanghai' > /etc/timezone

# 安装构建依赖（精简版本）
RUN apt-get update -y \
    && apt-get install -y --no-install-recommends \
        python3-pip \
        python3-dev \
        git \
        build-essential \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# 设置 Python 链接
RUN ln -s /usr/bin/python3 /usr/bin/python

# 安装 Poetry
RUN pip install --no-cache-dir -U pip setuptools wheel poetry==1.8.3 \
    && poetry config virtualenvs.create false \
    && poetry config installer.max-workers 10

WORKDIR /tmp

# 复制依赖文件
COPY pyproject.toml poetry.lock ./

# 安装 Python 依赖（包括 GPU 组）
RUN poetry install --no-root --with=gpu \
    && pip cache purge

# 复制源代码并构建
COPY coral_inference /tmp/coral_inference
RUN poetry build

# 运行阶段
FROM nvcr.io/nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04 AS runtime

ENV TZ="Asia/Shanghai"
ARG DEBIAN_FRONTEND=noninteractive

WORKDIR /app

# Set timezone
RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && \
    echo 'Asia/Shanghai' > /etc/timezone

# 安装运行时依赖（精简版本）
RUN apt-get update -y \
    && apt-get install -y --no-install-recommends \
        libxext6 \
        libopencv-dev \
        python3-pip \
        libgdal-dev \
        libgomp1 \
        libx264-dev \
        x264 \
        libavcodec-extra \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# 设置 Python 链接
RUN ln -s /usr/bin/python3 /usr/bin/python

# 从构建阶段复制 Python 包（保持路径一致）
COPY --from=builder /usr/local/lib/python3.*/dist-packages /usr/local/lib/python3.10/dist-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# 从构建阶段复制构建的 wheel 包并安装
COPY --from=builder /tmp/dist/*.whl /tmp/
RUN pip install --no-cache-dir /tmp/*.whl \
    && rm -rf /tmp/*.whl \
    && pip cache purge

# 复制配置文件
COPY docker/config /app/
RUN chmod +x ./entrypoint.sh

# Environment variables
ENV VERSION_CHECK_MODE=continuous \
    PROJECT=coral-platform \
    NUM_WORKERS=1 \
    HOST=0.0.0.0 \
    PORT=9001 \
    WORKFLOWS_STEP_EXECUTION_MODE=local \
    WORKFLOWS_MAX_CONCURRENT_STEPS=4 \
    # API_LOGGING_ENABLED=True \
    # LMM_ENABLED=False \
    # CORE_MODEL_SAM2_ENABLED=False \
    # CORE_MODEL_OWLV2_ENABLED=False \
    ENABLE_STREAM_API=True \
    # ENABLE_WORKFLOWS_PROFILING=True \
    ENABLE_PROMETHEUS=True \
    METRICS_ENABLED=True \
    CURRENT_INFERENCE_PLATFORM=onnx

ENTRYPOINT ["./entrypoint.sh"]