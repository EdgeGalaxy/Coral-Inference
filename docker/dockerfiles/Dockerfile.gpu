FROM nvcr.io/nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04 

WORKDIR /app

# 缓存层1: 安装系统依赖（很少变化）
RUN apt-get update -y && DEBIAN_FRONTEND=noninteractive apt-get install -y \
    libxext6 \
    libopencv-dev \
    uvicorn \
    python3-pip \
    git \
    libgdal-dev \
    wget \
    && rm -rf /var/lib/apt/lists/*

# 缓存层2: 设置Python链接（很少变化）
RUN ln -s /usr/bin/python3 /usr/bin/python

# 缓存层3: 安装Python构建工具（很少变化）
RUN pip install --no-cache-dir -U pip setuptools wheel poetry \
    && poetry config virtualenvs.create false

WORKDIR /tmp

# 缓存层4: 复制依赖文件（偶尔变化）
COPY pyproject.toml poetry.lock ./

# 缓存层5: 安装基础依赖（不包括可选的GPU组）
RUN poetry install --no-root --group gpu


COPY coral_inference /tmp/coral_inference

RUN poetry build && \
    pip install --no-cache-dir dist/*.whl


WORKDIR /app

# 缓存层4: 复制配置文件（偶尔变化）
COPY docker/config /app/

# 缓存层5: 设置权限（配置文件变化时重新构建）
RUN chmod +x ./entrypoint.sh

# Environment variables
ENV VERSION_CHECK_MODE=continuous \
    PROJECT=coral-platform \
    NUM_WORKERS=1 \
    HOST=0.0.0.0 \
    PORT=9001 \
    WORKFLOWS_STEP_EXECUTION_MODE=local \
    WORKFLOWS_MAX_CONCURRENT_STEPS=4 \
    API_LOGGING_ENABLED=True \
    LMM_ENABLED=False \
    CORE_MODEL_SAM2_ENABLED=False \
    CORE_MODEL_OWLV2_ENABLED=False \
    ENABLE_STREAM_API=True \
    ENABLE_WORKFLOWS_PROFILING=True \
    ENABLE_PROMETHEUS=True \
    CURRENT_INFERENCE_PLATFORM=onnx

ENTRYPOINT ["./entrypoint.sh"]